# Pragmatic Batch Processing Test Plan
**For Demo-Stage Product (20 Users Max)**
**‚úÖ STATUS: ACTIVE - This is our current testing approach**

> **IMPLEMENTED**: See `tests/batch/test_batch_pragmatic.py` for the actual test suite.
> The comprehensive test plan (BATCH_PROCESSING_TEST_PLAN.md) is deferred for future scaling.

## Testing Philosophy
- **Accuracy over scale** - Traders need correct numbers, not fast ones
- **Manual verification acceptable** - We're not at automation scale yet
- **Focus on demo scenarios** - Test what we'll actually show
- **Skip premature optimization** - No need for 1000-position portfolios yet
- **‚ö†Ô∏è REALITY FIRST** - Test basic functionality before complex scenarios

---

## 0. REALITY CHECK TESTING (ADDED 2025-01-06)
**üîç Test what exists before testing what should work**

### 0.1 Import and Dependency Validation
**This MUST pass before any other testing**

```python
# tests/batch/test_reality_check.py

def test_critical_imports():
    """Test if core components can even be imported"""
    
    # Test 1: APScheduler installed?
    try:
        import apscheduler
        print("‚úì APScheduler available")
    except ImportError:
        print("‚ùå APScheduler not installed - run: uv add apscheduler")
        return False
    
    # Test 2: Batch orchestrator imports?
    try:
        from app.batch.batch_orchestrator import batch_orchestrator
        print("‚úì Batch orchestrator imports")
    except Exception as e:
        print(f"‚ùå Batch orchestrator import failed: {e}")
        return False
    
    # Test 3: Admin endpoints work?
    try:
        from app.api.v1.endpoints.admin_batch import router
        print("‚úì Admin endpoints import")
    except Exception as e:
        print(f"‚ùå Admin endpoints broken: {e}")
        return False
        
    return True
```

### 0.2 Function Mapping Validation  
**Ensure orchestrator calls match actual function names**

```python
def test_calculation_engine_mapping():
    """Test that orchestrator calls functions that actually exist"""
    
    engines_to_test = {
        'Greeks': ('app.calculations.greeks', 'bulk_update_portfolio_greeks'),
        'Portfolio': ('app.calculations.portfolio', 'calculate_portfolio_exposures'),
        'Factors': ('app.calculations.factors', 'calculate_factor_betas_hybrid'),
        'Correlations': ('app.services.correlation_service', 'CorrelationService'),
        'Snapshots': ('app.calculations.snapshots', 'create_portfolio_snapshot'),
    }
    
    working = []
    broken = []
    
    for name, (module, function) in engines_to_test.items():
        try:
            exec(f"from {module} import {function}")
            working.append(name)
            print(f"‚úì {name}: {function} exists")
        except ImportError as e:
            broken.append((name, str(e)))
            print(f"‚ùå {name}: {function} missing - {e}")
    
    print(f"\nWorking engines: {len(working)}/5")
    print(f"Broken engines: {len(broken)}/5")
    
    return len(working) >= 3  # Need at least 3 working engines for demo
```

### 0.3 Database Connectivity Test
**Before testing complex batch jobs, ensure basic DB works**

```python
async def test_minimal_database_function():
    """Test absolute minimum database functionality"""
    
    from app.models.snapshots import BatchJob
    from app.core.database import AsyncSessionLocal
    from sqlalchemy import text
    
    try:
        async with AsyncSessionLocal() as db:
            # Test 1: Basic query works?
            result = await db.execute(text("SELECT 1 as test"))
            assert result.fetchone()[0] == 1
            print("‚úì Database connectivity works")
            
            # Test 2: Can create BatchJob?
            job = BatchJob(
                job_name="reality_check",
                job_type="test",
                status="running"
            )
            db.add(job)
            await db.commit()
            print(f"‚úì BatchJob creation works: {job.id}")
            
            return True
            
    except Exception as e:
        print(f"‚ùå Database basic function failed: {e}")
        return False
```

### 0.4 Reality Check Test Suite
**Run this FIRST before any other testing**

```python
async def run_reality_check():
    """
    Complete reality check - run this before attempting complex tests
    """
    print("üîç BATCH PROCESSING REALITY CHECK")
    print("="*50)
    
    # Step 1: Imports and dependencies
    imports_ok = test_critical_imports()
    if not imports_ok:
        print("\n‚ùå STOP: Fix import issues before proceeding")
        return False
    
    # Step 2: Function mapping
    functions_ok = test_calculation_engine_mapping()  
    if not functions_ok:
        print("\n‚ùå STOP: Fix function mapping before proceeding")
        return False
    
    # Step 3: Database basics
    db_ok = await test_minimal_database_function()
    if not db_ok:
        print("\n‚ùå STOP: Fix database issues before proceeding")
        return False
    
    print("\n‚úÖ REALITY CHECK PASSED")
    print("Ready for functional testing")
    return True
```

**üö® CRITICAL: Run reality check before every test session**
```bash
# Before any batch testing:
PYTHONPATH=/path/to/project uv run python -c "
import asyncio
from tests.batch.test_reality_check import run_reality_check
asyncio.run(run_reality_check())
"
```

---

## 1. Critical Path Testing Only (What Actually Matters)

### 1.1 Accuracy Validation (MOST IMPORTANT)
```python
# tests/batch/test_accuracy.py

async def test_calculation_accuracy_for_demo():
    """Verify calculations match trader expectations"""
    
    # Use Growth Investor portfolio (most likely demo)
    portfolio_id = 1
    
    # Run the batch sequence
    await run_daily_batch_sequence(portfolio_id)
    
    # MANUAL VERIFICATION POINTS:
    # 1. Greeks: Check 1-2 options positions manually
    aapl_call = await get_position_greek("AAPL_250117C00200000")
    print(f"AAPL Call Delta: {aapl_call.delta}")  # Should be ~0.55
    # Trader can verify: "Yes, that delta looks right for ATM call"
    
    # 2. Portfolio Value: Compare to Bloomberg/broker
    snapshot = await get_latest_snapshot(portfolio_id)
    print(f"Total Portfolio Value: ${snapshot.total_market_value:,.2f}")
    # Compare to TD Ameritrade: Should match within 1%
    
    # 3. Factor Exposures: Sanity check
    factors = await get_factor_exposures(portfolio_id)
    spy_beta = next(f for f in factors if f.factor == "SPY").beta
    print(f"Portfolio Beta to S&P: {spy_beta}")
    # Should be between 0.8-1.2 for typical portfolio
```

### 1.2 Demo Scenario Testing
```python
async def test_demo_scenarios():
    """Test exactly what we'll show in demos"""
    
    # Scenario 1: Daily update at market close
    await simulate_market_close()
    await run_daily_batch_sequence(portfolio_id=1)
    
    # Check the dashboard shows updated values
    dashboard_data = await get_dashboard_data(portfolio_id=1)
    assert dashboard_data.last_updated.date() == date.today()
    assert dashboard_data.total_value > 0
    
    # Scenario 2: Stress test presentation
    stress_results = await get_latest_stress_test(portfolio_id=1)
    
    # Just verify we have results to show
    assert len(stress_results.scenarios) >= 5  # At least 5 scenarios
    assert "Market Crash -20%" in [s.name for s in stress_results.scenarios]
    # Don't need to verify math - just that we have presentable data
```

---

## 2. Scale Testing (For 20 Users)

### 2.1 Concurrent User Test
```python
async def test_20_user_scale():
    """Ensure system handles 20 users (not 20,000)"""
    
    # Create 20 test portfolios (or use 3 demo portfolios x 7 times)
    portfolio_ids = [1, 2, 3] * 7  # Reuse demo portfolios
    
    # Run batch for all "20 users"
    start = time.time()
    for pid in portfolio_ids:
        await run_daily_batch_sequence(pid)
    duration = time.time() - start
    
    # Acceptable: Under 30 minutes for all 20
    assert duration < 1800  # 30 minutes is fine for batch
    print(f"Processed 20 portfolios in {duration/60:.1f} minutes")
```

### 2.2 Database Load Test
```python
async def test_database_capacity():
    """Ensure database handles demo scale"""
    
    # We have 3 portfolios x 21 positions = 63 positions
    # At 20 users with similar portfolios = ~1,260 positions
    # This is tiny for PostgreSQL
    
    position_count = await db.query("SELECT COUNT(*) FROM positions")
    print(f"Total positions in system: {position_count}")
    
    # Just verify basic queries still work
    query_time = await measure_query_time(
        "SELECT * FROM positions WHERE portfolio_id = 1"
    )
    assert query_time < 0.1  # Under 100ms is fine
```

---

## 3. Simplified Failure Testing

### 3.1 Market Data Failure (Most Likely Issue)
```python
async def test_polygon_api_failure_handling():
    """Test handling of Polygon API failures (most common issue)"""
    
    # Simulate Polygon being down
    with patch('app.clients.polygon_client.get_latest_price') as mock:
        mock.side_effect = Exception("Polygon API timeout")
        
        # Run batch - should use cached prices
        result = await run_daily_batch_sequence(portfolio_id=1)
        
        # Should complete with warnings, not fail
        assert result.status == "completed_with_warnings"
        assert "Using cached prices" in result.warnings
        
        # Dashboard should still show data (with stale warning)
        dashboard = await get_dashboard_data(portfolio_id=1)
        assert dashboard.data_status == "stale"
        assert dashboard.total_value > 0  # Still shows something
```

### 3.2 Calculation Engine Failure
```python
async def test_partial_calculation_failure():
    """If Greeks fail, everything else should still work"""
    
    # Break Greeks calculation
    with patch('app.calculations.greeks.calculate_portfolio_greeks') as mock:
        mock.side_effect = Exception("Greeks calculation failed")
        
        await run_daily_batch_sequence(portfolio_id=1)
        
        # Portfolio value should still update
        snapshot = await get_latest_snapshot(portfolio_id=1)
        assert snapshot.total_market_value > 0
        
        # Greeks should be null but noted
        assert snapshot.greeks_available == False
        assert snapshot.notes == "Greeks calculation failed - using previous values"
```

---

## 4. Manual Testing Checklist (For Demo Prep)

### Before Each Demo:
- [ ] Run batch manually at 3:30 PM
- [ ] Check dashboard loads properly
- [ ] Verify portfolio value looks reasonable (compare to yesterday)
- [ ] Click through to stress test results
- [ ] Ensure no error messages visible

### Weekly Checks:
- [ ] Tuesday: Verify correlation calculation ran
- [ ] Compare portfolio values to broker statements
- [ ] Check that all 3 demo portfolios updated
- [ ] Review batch job logs for any warnings

### If Something Looks Wrong:
1. Check `batch_jobs` table for errors
2. Re-run specific job manually via admin endpoint
3. Use cached/yesterday's data if needed
4. Have backup slides with pre-calculated results

---

## 5. What We're NOT Testing (Intentionally)

### Skip These Tests:
- ‚ùå 1000+ position portfolios (not needed yet)
- ‚ùå Sub-second response times (batch is fine being slow)
- ‚ùå Automated alerting (just check logs manually)
- ‚ùå Complex retry logic (just re-run manually if needed)
- ‚ùå Memory optimization (20 users won't stress memory)
- ‚ùå Distributed processing (single server is fine)
- ‚ùå Real-time updates (daily batch is sufficient)

---

## 6. Practical Test Execution Plan

### Week Before Demo:
**Monday**: 
- Run full batch with all 3 demo portfolios
- Screenshot results for backup slides

**Tuesday**: 
- Verify correlation calculation works
- Note any data quality issues

**Wednesday-Thursday**: 
- Daily batch runs
- Compare values to external sources
- Fix any calculation bugs found

**Friday**: 
- Final test run
- Document all "known issues" to avoid surprises
- Prepare explanation for any quirks

### Day of Demo:
- Run batch 2 hours before demo
- Quick manual verification of key numbers
- Have yesterday's data as backup

---

## 7. Success Criteria (Realistic)

### Must Have:
‚úÖ Portfolio values within 2% of broker statements  
‚úÖ Greeks look reasonable to a trader's eye  
‚úÖ Stress tests produce believable scenarios  
‚úÖ No visible errors on dashboard  
‚úÖ Batch completes within 30 minutes for all portfolios  

### Nice to Have:
üìä All calculations within 1% accuracy  
üìä Batch completes in under 10 minutes  
üìä Automatic recovery from API failures  

### Don't Need Yet:
‚ùå 99.99% uptime  
‚ùå Sub-second calculations  
‚ùå Handling 1000+ concurrent users  

---

## 8. Test Data Strategy

### Use Real Demo Portfolios:
```python
# These are already seeded and realistic
portfolio_1 = "Growth Investor"  # Mixed stocks/options
portfolio_2 = "Hedge Fund"       # Complex strategies  
portfolio_3 = "Retail Trader"    # Simple portfolio

# Test with these exact portfolios
# Traders can relate to these in demos
```

### Manual Baseline Validation:
```excel
# Create simple Excel sheet with expected values:
Portfolio         | Expected Value | Our System | Difference
Growth Investor   | $1,000,000    | $998,500   | -0.15%
Hedge Fund        | $5,000,000    | $5,012,000 | +0.24%
Retail Trader     | $100,000      | $99,750    | -0.25%

# If within 1%, we're good for demo
```

---

## 9. UPDATED TEST STRATEGY (Based on Reality Check Results)

### 9.1 What We Learned (2025-01-06)
**Our original test plan assumed a working system. Reality check revealed:**

‚ùå **Original Assumption**: "Test calculation accuracy for demo"  
‚úÖ **Reality**: Can't even import the orchestrator - fix imports first

‚ùå **Original Assumption**: "Test 20-user scale"  
‚úÖ **Reality**: APScheduler not installed - add dependencies first  

‚ùå **Original Assumption**: "Test demo scenarios"  
‚úÖ **Reality**: Function names don't match - fix API mapping first

### 9.2 Revised Testing Priority (Reality-Based)

**Phase 0: Make it importable (2-4 hours)**
1. Install APScheduler: `uv add apscheduler`  
2. Fix function name mappings in orchestrator
3. Add missing `require_admin` dependency
4. Fix SQL text expression issues

**Phase 1: Make it minimally functional (4-8 hours)**
1. Get one calculation engine working end-to-end
2. Create one batch job successfully  
3. Test with one demo portfolio
4. Manual verification of basic numbers

**Phase 2: Add demo readiness (1-2 days)**  
1. Test with all 3 demo portfolios
2. Manual verification against broker statements
3. Test admin endpoints for demo recovery
4. Create backup slides with pre-calculated results

**Phase 3: Scale testing (deferred until Phase 2 works)**
- Only test 20-user scale after basic functionality proven
- Focus on "does it work" before "does it scale"

### 9.3 Pragmatic Success Criteria (Updated)

**Must Have Before Demo:**  
‚úÖ Orchestrator imports without errors  
‚úÖ Can create and update batch jobs in database  
‚úÖ At least 3 calculation engines working  
‚úÖ One complete portfolio calculation succeeds  
‚úÖ Results look reasonable to trader eye-test  

**Nice to Have:**  
üìä All 7 calculation engines working  
üìä Automated daily scheduling  
üìä Complete admin panel functionality  

**Don't Need for Demo:**  
‚ùå Perfect accuracy (within 2% is fine)  
‚ùå All error handling edge cases  
‚ùå Performance optimization  
‚ùå Automated monitoring/alerts  

### 9.4 Test-Driven Fix Approach

Instead of fixing everything then testing, use tests to guide fixes:

```python
# Fix Step 1: Can we import?
def test_import_fix():
    from app.batch.batch_orchestrator import batch_orchestrator  # Should work
    
# Fix Step 2: Can we create a job?  
async def test_job_creation():
    job = await batch_orchestrator._create_batch_job("test")  # Should work
    
# Fix Step 3: Can we run one calculation?
async def test_single_calculation():
    result = await batch_orchestrator._calculate_portfolio_aggregation(db, portfolio_id)
    assert result is not None  # Should work
```

**Fix until tests pass, then move to next level of testing.**

---

## 10. Emergency Demo Procedures

### If Batch Fails Day-of:
1. Use yesterday's snapshot (usually fine)
2. Say "values as of yesterday's close" 
3. Run calculations live if needed (single portfolio is fast)
4. Have static slides with pre-calculated results

### Common Issues & Solutions:
| Issue | Quick Fix | Explanation for Demo |
|-------|-----------|---------------------|
| Polygon API down | Use cached prices | "Using last available market data" |
| Greeks missing | Hide Greeks panel | "Options analytics updating" |
| Stress test fails | Use last week's | "Stress tests run weekly" |
| Wrong values | Blame market volatility | "Reflecting this morning's gap" |

---

## 10. Documentation for Demo Team

### What to tell traders:
- "Calculations run daily at market close"
- "All risk metrics updated overnight"
- "Real-time prices available on request" (run manual update)
- "System designed for institutional accuracy"

### What NOT to promise:
- Real-time streaming updates
- Microsecond latency
- 100% uptime
- Handling their 50,000 position portfolio

---

## Summary (Updated Based on Reality Check)

**ORIGINAL PLAN** (assumed working system):
- Focus on accuracy, demo scenarios, 20-user scale
- Time needed: 2-3 days of testing

**REVISED PLAN** (based on what actually exists):
- **Phase 0**: Make it importable (fix dependencies, function names) - 2-4 hours
- **Phase 1**: Make it minimally functional (one engine working) - 4-8 hours  
- **Phase 2**: Demo readiness (3 portfolios, manual verification) - 1-2 days
- **Phase 3**: Scale testing (deferred until Phase 2 works)

**KEY LEARNING**: Always run reality check before functional testing
**Test method**: Test-driven fixes ‚Üí manual verification ‚Üí automated checks  
**Total time**: 2-3 days (same), but front-loaded with basic functionality fixes

**This is appropriate for a demo-stage product, but we learned that "completed" code may not be functional without proper testing validation.**